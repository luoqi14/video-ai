import os
from google import genai
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import StreamingResponse
from typing import Optional, AsyncGenerator, Dict
from fastapi.middleware.cors import CORSMiddleware
import tempfile
import os
import time
import hashlib
from pydantic import BaseModel
from dotenv import load_dotenv
from google.genai import types
import asyncio
import json
import uuid

# Load environment variables from .env file
load_dotenv()

# --- Progress Management ---
class ProcessProgress:
    def __init__(self):
        self.task_id: str = ""
        self.stage: str = "idle"  # idle, uploading, google_processing, ai_generating, streaming, complete, error
        self.percentage: int = 0
        self.message: str = ""
        self.start_time: float = 0
        self.error_message: str = ""
        self.result: Optional[Dict] = None
        # æµå¼å“åº”æ”¯æŒ
        self.streaming_text: str = ""
        self.is_streaming: bool = False
        self.stream_complete: bool = False
    
    def update(self, stage: str, percentage: int, message: str = ""):
        self.stage = stage
        self.percentage = percentage
        self.message = message
        if stage == "error":
            self.error_message = message
        print(f"Progress Update [{self.task_id}]: {stage} - {percentage}% - {message}")
    
    def append_streaming_text(self, text: str):
        """æ·»åŠ æµå¼æ–‡æœ¬"""
        self.streaming_text += text
        self.is_streaming = True
    
    def complete_streaming(self):
        """æ ‡è®°æµå¼å®Œæˆ"""
        self.is_streaming = False
        self.stream_complete = True

# å…¨å±€è¿›åº¦å­˜å‚¨
progress_store: Dict[str, ProcessProgress] = {}

# --- Global State for Current Video (Simple In-Memory) ---
class CurrentVideoState:
    def __init__(self):
        self.google_file_name: Optional[str] = None
        self.original_file_name: Optional[str] = None
        self.mime_type: Optional[str] = None
        self.file_hash: Optional[str] = None  # æ·»åŠ æ–‡ä»¶å“ˆå¸Œç”¨äºç¼“å­˜

current_video_state = CurrentVideoState()

# --- Helper Functions ---
def calculate_file_hash(file_content: bytes) -> str:
    """è®¡ç®—æ–‡ä»¶å†…å®¹çš„SHA256å“ˆå¸Œå€¼"""
    return hashlib.sha256(file_content).hexdigest()

# --- Global Variables & Configuration ---
load_dotenv(os.path.join(os.path.dirname(__file__), '.env'))
API_KEY = os.getenv("GOOGLE_API_KEY")
MODEL_NAME = "gemini-2.5-flash" # Using a stable model name

if not API_KEY:
    raise RuntimeError("GOOGLE_API_KEY not found in .env file")

# Initialize the new client, this is the recommended approach for the new SDK
client = genai.Client(api_key=API_KEY)

app = FastAPI()

# --- CORS Middleware ---
# This allows your frontend (running on localhost:3000) to communicate with this backend.
origins = [
    "http://localhost:3002",
    "http://127.0.0.1:3002",
    "https://video.jarvismedical.asia",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- API Endpoints ---
@app.get("/")
async def root():
    return {"message": "Video AI Backend is running"}

@app.get("/api/progress/{task_id}")
async def get_progress(task_id: str):
    """è·å–ä»»åŠ¡è¿›åº¦"""
    if task_id not in progress_store:
        raise HTTPException(status_code=404, detail="Task not found")
    
    progress = progress_store[task_id]
    return {
        "task_id": progress.task_id,
        "stage": progress.stage,
        "percentage": progress.percentage,
        "message": progress.message,
        "error_message": progress.error_message,
        "elapsed_time": time.time() - progress.start_time if progress.start_time > 0 else 0,
        "result": progress.result,
        "streaming_text": progress.streaming_text,
        "is_streaming": progress.is_streaming,
        "stream_complete": progress.stream_complete
    }

@app.get("/api/stream/{task_id}")
async def stream_ai_response(task_id: str):
    """SSEæµå¼AIå“åº”"""
    
    print(f"[SSE] å®¢æˆ·ç«¯è¿æ¥æµå¼ç«¯ç‚¹ï¼Œä»»åŠ¡ID: {task_id}")
    
    def create_sse_data(data: Dict) -> str:
        return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    async def event_stream():
        if task_id not in progress_store:
            print(f"[SSE] ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}")
            yield create_sse_data({"error": "Task not found"})
            return
            
        progress = progress_store[task_id]
        last_text_length = 0
        
        print(f"[SSE] å¼€å§‹ç­‰å¾…AIç”Ÿæˆï¼Œå½“å‰é˜¶æ®µ: {progress.stage}")
        
        # ç­‰å¾…AIå¼€å§‹ç”Ÿæˆ
        while progress.stage not in ["ai_generating", "streaming", "complete", "error"]:
            await asyncio.sleep(0.1)
            if progress.stage == "error":
                print(f"[SSE] å‘ç°é”™è¯¯çŠ¶æ€: {progress.error_message}")
                yield create_sse_data({"type": "error", "message": progress.error_message})
                return
        
        print(f"[SSE] AIç”Ÿæˆé˜¶æ®µå¼€å§‹ï¼Œè¿›å…¥æµå¼æ¨¡å¼")
        
        # æŒç»­å‘é€æµå¼æ›´æ–°
        while not progress.stream_complete and progress.stage != "error":
            current_text_length = len(progress.streaming_text)
            
            # å‘é€æ–°çš„æ–‡æœ¬å—
            if current_text_length > last_text_length:
                new_text = progress.streaming_text[last_text_length:]
                print(f"[SSE] å‘é€æ–‡æœ¬å—: {repr(new_text)}")
                yield create_sse_data({
                    "type": "chunk",
                    "text": new_text,
                    "accumulated_text": progress.streaming_text
                })
                last_text_length = current_text_length
            
            await asyncio.sleep(0.1)  # 100msè½®è¯¢é—´éš”
        
        # å‘é€å®Œæˆä¿¡å·
        if progress.stream_complete:
            yield create_sse_data({
                "type": "complete", 
                "final_text": progress.streaming_text,
                "result": progress.result
            })
        elif progress.stage == "error":
            yield create_sse_data({"type": "error", "message": progress.error_message})
    
    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

@app.post("/api/start-processing")
async def start_processing(prompt: str = Form(...), video_file: Optional[UploadFile] = File(None)):
    """å¯åŠ¨å¼‚æ­¥å¤„ç†ä»»åŠ¡å¹¶è¿”å›ä»»åŠ¡ID"""
    task_id = str(uuid.uuid4())
    progress = ProcessProgress()
    progress.task_id = task_id
    progress.start_time = time.time()
    progress.update("starting", 0, "å¼€å§‹å¤„ç†è¯·æ±‚...")
    progress_store[task_id] = progress
    
    # é¢„å…ˆè¯»å–è§†é¢‘æ–‡ä»¶å†…å®¹ï¼Œé¿å…åå°ä»»åŠ¡ä¸­çš„æ–‡ä»¶å¥æŸ„å…³é—­é—®é¢˜
    video_content = None
    video_mime_type = None
    video_filename = None
    
    if video_file and video_file.filename:
        try:
            video_content = await video_file.read()
            video_mime_type = video_file.content_type
            video_filename = video_file.filename
            print(f"Successfully read video file in start_processing: {video_filename}, size: {len(video_content)}")
        except Exception as e:
            print(f"Error reading video file in start_processing: {str(e)}")
            progress.update("error", 0, f"è¯»å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
            return {"error": f"è¯»å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}"}
    
    # å¯åŠ¨åå°ä»»åŠ¡ï¼Œä¼ é€’å·²è¯»å–çš„æ–‡ä»¶å†…å®¹è€Œä¸æ˜¯æ–‡ä»¶å¯¹è±¡
    asyncio.create_task(process_video_task_with_content(task_id, prompt, video_content, video_mime_type, video_filename))
    
    return {"task_id": task_id}

# --- Tool Definition for Video + Subtitles --- 
execute_ffmpeg_with_optional_subtitles_declaration = types.FunctionDeclaration(
    name="execute_ffmpeg_with_optional_subtitles",
    description=(
        "Executes an FFmpeg command in the user's web browser using FFmpeg.wasm and can optionally include subtitles. "
        "Use this tool when the user asks to perform video manipulations like trimming, converting, adding subtitles, etc. "
        "The input video file is always named 'input.mp4' in the FFmpeg.wasm environment. "
        "Provide the full FFmpeg command string, the desired output filename for the video, "
        "the content of the subtitles (if requested or appropriate, in SRT or VTT format), "
        "and a filename for the subtitles (e.g., 'subs.srt' or 'subs.vtt'). "
        "If subtitles are not requested or not applicable, subtitles_content and subtitles_filename can be omitted or empty."
    ),
    parameters=types.Schema(
        type=types.Type.OBJECT,
        properties={
            "command_array": types.Schema(
                type=types.Type.ARRAY,
                items=types.Schema(type=types.Type.STRING),
                description="The FFmpeg command arguments as an array of strings (without 'ffmpeg' at the beginning). For subtitles, use EXACT syntax: 'subtitles=filename.srt:fontsdir=/customfonts:force_style=\\'Fontname=Source Han Sans SC\\'' (CRITICAL: use 'fontsdir' NOT 'fontsize'). Example: ['-i', 'input.mp4', '-vf', 'subtitles=subs.srt:fontsdir=/customfonts:force_style=\\'Fontname=Source Han Sans SC\\'', 'output.mp4']"
            ),
            "output_filename": types.Schema(
                type=types.Type.STRING,
                description="The desired name for the output video file, e.g., 'output_with_subs.mp4', 'trimmed_video.mp4'."
            ),
            "subtitles_content": types.Schema(
                type=types.Type.STRING,
                description="The actual content of the subtitles (e.g., SRT or VTT format). Omit or leave empty if no subtitles are generated."
            ),
            "subtitles_filename": types.Schema(
                type=types.Type.STRING,
                description="The filename for the subtitles (e.g., 'subs.srt', 'subs.vtt'). Omit or leave empty if no subtitles are generated. This filename should be used in the command_string if burning subtitles."
            )
        },
        required=["command_array", "output_filename"] 
    )
)

async def process_video_task_with_content(task_id: str, prompt: str, video_content: Optional[bytes], video_mime_type: Optional[str], video_filename: Optional[str]):
    """å¼‚æ­¥å¤„ç†è§†é¢‘çš„åå°ä»»åŠ¡ï¼Œæ¥å—å·²è¯»å–çš„æ–‡ä»¶å†…å®¹"""
    progress = progress_store[task_id]
    
    try:
        progress.update("initializing", 2, "åˆå§‹åŒ–å¤„ç†æµç¨‹...")
        print(f"Received prompt for video processing: {prompt}, and video: {video_filename if video_filename else 'No new video file provided (will attempt to use previous)'}")
        
        file_object_for_gemini: Optional[types.File] = None
        original_video_filename_for_prompt: str = "input.mp4" # Default
        temp_file_path = None # Initialize for cleanup

        if video_content and video_filename: # New video file is provided
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œä»¥æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
            new_file_hash = calculate_file_hash(video_content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
            if (current_video_state.file_hash == new_file_hash and 
                current_video_state.google_file_name and 
                current_video_state.original_file_name == video_filename):
                
                progress.update("google_processing", 20, f"â™»ï¸ æ£€æµ‹åˆ°ç›¸åŒè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ç¼“å­˜: {video_filename}")
                print(f"â™»ï¸ Same video file detected (hash: {new_file_hash[:8]}...), using cached version: {current_video_state.google_file_name}")
                
                # éªŒè¯ç¼“å­˜çš„æ–‡ä»¶æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                retrieved_file = await asyncio.to_thread(client.files.get, name=current_video_state.google_file_name)
                if retrieved_file and retrieved_file.state and retrieved_file.state.name == "ACTIVE":
                    progress.update("google_processing", 50, "âœ… ç¼“å­˜æ–‡ä»¶éªŒè¯é€šè¿‡")
                    file_object_for_gemini = retrieved_file
                    original_video_filename_for_prompt = current_video_state.original_file_name
                else:
                    progress.update("uploading", 5, "âš ï¸ ç¼“å­˜æ–‡ä»¶æ— æ•ˆï¼Œé‡æ–°ä¸Šä¼ ")
                    print(f"âš ï¸ Cached file is invalid, re-uploading: {current_video_state.google_file_name}")
                    # æ¸…é™¤æ— æ•ˆç¼“å­˜
                    current_video_state.google_file_name = None
                    current_video_state.file_hash = None
                    # ç»§ç»­æ‰§è¡Œä¸Šä¼ é€»è¾‘
            else:
                progress.update("uploading", 5, f"ğŸ“¤ å¼€å§‹å¤„ç†æ–°è§†é¢‘æ–‡ä»¶: {video_filename}")
                print(f"ğŸ“¤ Processing new video file: {video_filename} (hash: {new_file_hash[:8]}...)")
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ç¼“å­˜æ–‡ä»¶ï¼Œåˆ™ä¸Šä¼ æ–°æ–‡ä»¶
            if not file_object_for_gemini:
                progress.update("uploading", 10, "ä¿å­˜ä¸´æ—¶æ–‡ä»¶...")
                # Create temp file
                file_suffix = os.path.splitext(video_filename)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp:
                    tmp.write(video_content)
                    temp_file_path = tmp.name
                
                print(f"Video content (size: {len(video_content)}) saved to temp file: {temp_file_path}")
                
                progress.update("google_processing", 15, f"ä¸Šä¼ åˆ°GoogleæœåŠ¡å™¨: {video_filename}")
                print(f"Uploading temporary video file to Google: {video_filename}, mime_type: {video_mime_type}")

                upload_config = types.UploadFileConfig(
                    mime_type=video_mime_type,
                    display_name=video_filename
                )
                upload_start_time = time.time()
                
                uploaded_file_obj = await asyncio.to_thread(
                    client.files.upload,
                    file=temp_file_path,
                    config=upload_config
                )
                
                upload_duration = time.time() - upload_start_time
                print(f"PERF: client.files.upload took {upload_duration:.2f} seconds.")
                print(f"Initial file upload response. Name: {uploaded_file_obj.name}, Display Name: {uploaded_file_obj.display_name}, URI: {uploaded_file_obj.uri}, State: {uploaded_file_obj.state.name if uploaded_file_obj.state else 'UNKNOWN'}")
                
                progress.update("google_processing", 30, "ç­‰å¾…Googleå¤„ç†æ–‡ä»¶...")
                # Wait for file to be processed
                processing_wait_start_time = time.time()
                wait_cycles = 0
                while uploaded_file_obj.state and uploaded_file_obj.state.name == "PROCESSING":
                    wait_cycles += 1
                    # åŠ¨æ€æ›´æ–°è¿›åº¦å’Œæ¶ˆæ¯ï¼Œè®©ç”¨æˆ·çŸ¥é“ä»åœ¨å¤„ç†
                    progress_percent = min(30 + wait_cycles * 2, 45)  # ä»30%é€æ¸å¢åŠ åˆ°45%
                    progress.update("google_processing", progress_percent, f"Googleæ­£åœ¨å¤„ç†æ–‡ä»¶... ({wait_cycles}s)")
                    
                    print(f"File {uploaded_file_obj.name} is still PROCESSING. Waiting 1 seconds... (cycle {wait_cycles})")
                    await asyncio.sleep(1)
                    
                    retrieved_file = await asyncio.to_thread(client.files.get, name=uploaded_file_obj.name)
                    if retrieved_file and retrieved_file.state:
                        uploaded_file_obj = retrieved_file
                        print(f"Updated file state: {uploaded_file_obj.name} is now {uploaded_file_obj.state.name}")
                    else:
                        print(f"Warning: client.files.get for {uploaded_file_obj.name} returned invalid data or state. Retrying...")
                
                processing_wait_duration = time.time() - processing_wait_start_time
                print(f"PERF: File state change from PROCESSING to ACTIVE took {processing_wait_duration:.2f} seconds.")
                
                if not (uploaded_file_obj.state and uploaded_file_obj.state.name == "ACTIVE"):
                    progress.update("error", 0, f"ä¸Šä¼ çš„æ–‡ä»¶ {uploaded_file_obj.name} æœªèƒ½å˜ä¸ºå¯ç”¨çŠ¶æ€")
                    return
                
                progress.update("google_processing", 50, "æ–‡ä»¶å·²å‡†å¤‡å°±ç»ª")
                print(f"File {uploaded_file_obj.name} is ACTIVE.")
                current_video_state.google_file_name = uploaded_file_obj.name
                current_video_state.original_file_name = video_filename
                current_video_state.mime_type = video_mime_type
                current_video_state.file_hash = new_file_hash  # ä¿å­˜æ–‡ä»¶å“ˆå¸Œ
                file_object_for_gemini = uploaded_file_obj
                original_video_filename_for_prompt = video_filename

                # Clean up temp file
                if temp_file_path and os.path.exists(temp_file_path):
                    os.remove(temp_file_path)
                    print(f"Temporary file {temp_file_path} deleted.")
                        
        elif current_video_state.google_file_name:
            progress.update("google_processing", 20, f"ä½¿ç”¨å·²ä¸Šä¼ çš„è§†é¢‘: {current_video_state.original_file_name}")
            print(f"No new video file. Using last uploaded: {current_video_state.google_file_name} (Original: {current_video_state.original_file_name})")
            original_video_filename_for_prompt = current_video_state.original_file_name or "input.mp4"
            
            retrieved_file = await asyncio.to_thread(client.files.get, name=current_video_state.google_file_name)
            wait_cycles = 0
            while retrieved_file.state and retrieved_file.state.name == "PROCESSING":
                wait_cycles += 1
                # åŠ¨æ€æ›´æ–°è¿›åº¦ï¼Œè®©ç”¨æˆ·çŸ¥é“æ­£åœ¨éªŒè¯æ–‡ä»¶çŠ¶æ€
                progress_percent = min(20 + wait_cycles, 40)
                progress.update("google_processing", progress_percent, f"éªŒè¯å·²ç¼“å­˜æ–‡ä»¶çŠ¶æ€... ({wait_cycles}s)")
                
                print(f"File {retrieved_file.name} is PROCESSING. Waiting 1 seconds... (cycle {wait_cycles})")
                await asyncio.sleep(1)
                retrieved_file = await asyncio.to_thread(client.files.get, name=current_video_state.google_file_name)
            
            if not (retrieved_file.state and retrieved_file.state.name == "ACTIVE"):
                progress.update("error", 0, f"ä¹‹å‰ä¸Šä¼ çš„æ–‡ä»¶ {current_video_state.google_file_name} ä¸å¯ç”¨ï¼Œè¯·é‡æ–°ä¸Šä¼ ")
                return
            
            progress.update("google_processing", 50, "å·²ç¡®è®¤æ–‡ä»¶å¯ç”¨çŠ¶æ€")
            print(f"Successfully retrieved and confirmed ACTIVE status for {current_video_state.google_file_name}")
            file_object_for_gemini = retrieved_file
        else:
            progress.update("error", 0, "æœªæä¾›è§†é¢‘æ–‡ä»¶ä¸”æœªæ‰¾åˆ°ä¹‹å‰ä¸Šä¼ çš„è§†é¢‘")
            return

        # éªŒè¯ file_object_for_gemini æ˜¯å¦è¢«æ­£ç¡®è®¾ç½®
        if not file_object_for_gemini:
            progress.update("error", 0, "å†…éƒ¨é”™è¯¯ï¼šæ–‡ä»¶å¯¹è±¡æœªèƒ½æ­£ç¡®è®¾ç½®")
            print("ERROR: file_object_for_gemini is None - this should not happen")
            return

        # --- At this point, file_object_for_gemini and original_video_filename_for_prompt are set ---
        progress.update("ai_generating", 60, "å‡†å¤‡AIåˆ†æå’ŒæŒ‡ä»¤ç”Ÿæˆ...")

        # --- Construct the prompt for Gemini ---
        tool_config_video = types.Tool(function_declarations=[execute_ffmpeg_with_optional_subtitles_declaration])
        user_natural_language_prompt = prompt
        fixed_ffmpeg_input_filename = original_video_filename_for_prompt

        prompt_for_gemini = (
            f"You are a helpful AI assistant. The user has provided a video file named '{fixed_ffmpeg_input_filename}'.\n"
            f"The user's instruction is: '{user_natural_language_prompt}'.\n\n"
            f"IMPORTANT: Analyze the user's request carefully and choose the appropriate response type:\n\n"
            f"**TYPE 1 - Content Analysis (NO TOOLS)**: If the user wants to understand, analyze, or get information about the video content:\n"
            f"- Examples: 'summarize this video', 'what is in this video?', 'describe the content', 'what happens in the video?', 'analyze this video', 'tell me about this video'\n"
            f"- Action: Provide a direct text response by analyzing the video. DO NOT use any tools.\n\n"
            f"**TYPE 2 - Video Processing (USE TOOL)**: If the user wants to transform, edit, or modify the video file:\n"
            f"- Examples: 'convert to GIF', 'trim the video', 'extract audio', 'add subtitles', 'change format', 'resize video'\n"
            f"- Action: Call the 'execute_ffmpeg_with_optional_subtitles' tool.\n\n"
            f"**Current Request Analysis**: The instruction '{user_natural_language_prompt}' is asking for:\n"
            f"- If it's about understanding/analyzing content â†’ Provide direct text answer in Chinese\n"
            f"- If it's about editing/converting video â†’ Use the tool\n\n"
            f"**Tool Usage Details** (only if TYPE 2):\n"
            f"- The user's video is available as '{fixed_ffmpeg_input_filename}'. This MUST be the input file in your FFmpeg command.\n"
            f"- Generate the `command_array` (the arguments for FFmpeg, without 'ffmpeg' itself), the `output_filename`, and subtitle information if needed.\n"
            f"- **Subtitles**: If the instruction is about generating or burning in subtitles, create the content for 'subtitles_content' and a 'subtitles_filename'. When burning subtitles, your `command_array` MUST include the EXACT filter syntax:\n"
            f"  `subtitles=<subtitles_filename>:fontsdir=/customfonts:force_style='Fontname=Source Han Sans SC'`\n"
            f"  CRITICAL: Use 'fontsdir' NOT 'fontsize' or 'fontdir'. The correct parameter is 'fontsdir'.\n"
            f"  Example: For a subtitle file 'chinese_subs.srt', use:\n"
            f"  `['-i', 'input.mp4', '-vf', 'subtitles=chinese_subs.srt:fontsdir=/customfonts:force_style=\\'Fontname=Source Han Sans SC\\'', 'output.mp4']`\n"
            f"  The font 'SourceHanSansSC-Regular.otf' is available in '/customfonts'. If no subtitles are needed, provide empty strings for 'subtitles_content' and 'subtitles_filename'.\n\n"
            f"**CRITICAL: SRT Subtitle Format Requirements**:\n"
            f"If generating subtitles, the 'subtitles_content' MUST follow this EXACT SRT format:\n"
            f"```\n"
            f"1\n"
            f"00:00:01,500 --> 00:00:04,200\n"
            f"æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„è§†é¢‘\n"
            f"\n"
            f"2\n"
            f"00:00:05,300 --> 00:00:08,750\n"
            f"è®©æˆ‘ä»¬å¼€å§‹å­¦ä¹ å§\n"
            f"\n"
            f"3\n"
            f"00:00:10,000 --> 00:00:13,500\n"
            f"è¿™é‡Œæ˜¯ç¬¬ä¸‰æ®µå­—å¹•å†…å®¹\n"
            f"\n"
            f"```\n"
            f"MANDATORY SRT Rules:\n"
            f"1) Sequential numbering: 1, 2, 3, 4...\n"
            f"2) Time format: HH:MM:SS,mmm --> HH:MM:SS,mmm (use comma for milliseconds, NOT period)\n"
            f"   âœ… Correct: 00:00:01,500 --> 00:00:04,200\n"
            f"   âŒ Wrong: 00:00:01.500 --> 00:00:04.200\n"
            f"3) NO punctuation at sentence end: NO ã€‚ï¼Œï¼ï¼Ÿ\n"
            f"4) Empty line between subtitle blocks\n"
            f"5) Time ranges must match actual video content\n"
            f"6) Use reasonable subtitle duration (2-5 seconds per subtitle)\n"
            f"7) NO extra spaces, tabs, or special formatting\n\n"
            f"Now respond appropriately based on the request type."
        )

        # Explicitly create a Part for the video file, referencing it by URI and MIME type
        video_file_part = types.Part(
            file_data={
                'file_uri': file_object_for_gemini.uri,
                'mime_type': file_object_for_gemini.mime_type
            }
        )
        
        request_contents = [
            types.Part(text=prompt_for_gemini),
            video_file_part
        ]

        # --- Call Gemini API with Streaming and Process Response ---
        progress.update("ai_generating", 75, "å¼€å§‹æµå¼AIç”Ÿæˆ...")
        progress.update("streaming", 75, "AIæ­£åœ¨åˆ†æè§†é¢‘...")
        print(f"Sending to Gemini with streaming multimodal prompt (using file: {file_object_for_gemini.name if file_object_for_gemini else 'N/A'}) and tool: {execute_ffmpeg_with_optional_subtitles_declaration.name}")
        
        generate_content_start_time = time.time()
        
        # ä½¿ç”¨æµå¼API
        stream = await asyncio.to_thread(
            client.models.generate_content_stream,
            model=f'models/{MODEL_NAME}',
            contents=[types.Content(parts=request_contents)],
            config=types.GenerateContentConfig(
                tools=[types.Tool(function_declarations=[execute_ffmpeg_with_optional_subtitles_declaration])],
                tool_config=tool_config_video,
                temperature=0.3
            )
        )
        
        # å¤„ç†æµå¼å“åº”
        accumulated_response = None
        tool_call_result = None
        
        for chunk in stream:
            if chunk.candidates and len(chunk.candidates) > 0:
                candidate = chunk.candidates[0]
                
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        # å¤„ç†æ–‡æœ¬æµ
                        if hasattr(part, 'text') and part.text:
                            # Geminiè¿”å›çš„æ–‡æœ¬å—ï¼Œæˆ‘ä»¬éœ€è¦äººå·¥åˆ›å»ºæµå¼æ•ˆæœ
                            chunk_text = part.text
                            print(f"Geminiè¿”å›æ–‡æœ¬å— (é•¿åº¦: {len(chunk_text)}): {repr(chunk_text)}")
                            
                            # é€å­—ç¬¦æ·»åŠ ï¼Œåˆ›å»ºæµå¼æ•ˆæœ
                            for char in chunk_text:
                                progress.append_streaming_text(char)
                                # å°å»¶è¿Ÿä»¥åˆ›å»ºæ‰“å­—æœºæ•ˆæœï¼ˆå®é™…é¡¹ç›®ä¸­å¯ä»¥è°ƒæ•´æˆ–å»æ‰ï¼‰
                                await asyncio.sleep(0.02)  # 20msæ¯å­—ç¬¦
                        
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        elif hasattr(part, 'function_call') and part.function_call:
                            function_call = part.function_call
                            if function_call.name == execute_ffmpeg_with_optional_subtitles_declaration.name:
                                args = function_call.args
                                command_array = args.get("command_array")
                                output_filename = args.get("output_filename")
                                subtitles_content = args.get("subtitles_content", "") 
                                subtitles_filename = args.get("subtitles_filename", "")
                                
                                print(f"Gemini tool call received: {function_call.name} with args: {args}")
                                tool_call_result = {
                                    "tool_call": {
                                        "name": function_call.name,
                                        "arguments": {
                                            "command_array": command_array,
                                            "output_filename": output_filename,
                                            "subtitles_content": subtitles_content,
                                            "subtitles_filename": subtitles_filename
                                        }
                                    }
                                }
                
                # ä¿å­˜æœ€åçš„candidateç”¨äºæœ€ç»ˆæ£€æŸ¥
                accumulated_response = candidate
        
        generate_content_duration = time.time() - generate_content_start_time
        print(f"PERF: client.models.generate_content_stream took {generate_content_duration:.2f} seconds.")
        
        # å®Œæˆæµå¼ä¼ è¾“
        progress.complete_streaming()
        progress.update("ai_generating", 90, "å¤„ç†AIå›å¤...")
        
        # å¤„ç†æœ€ç»ˆç»“æœ
        if tool_call_result:
            # å·¥å…·è°ƒç”¨ç»“æœ
            progress.result = tool_call_result
            progress.update("complete", 100, "å·¥å…·è°ƒç”¨å®Œæˆ")
            return
        elif progress.streaming_text:
            # æ–‡æœ¬å“åº”
            result = {"text_response": progress.streaming_text.strip()}
            progress.result = result
            progress.update("complete", 100, "æ–‡æœ¬åˆ†æå®Œæˆ")
            return
        else:
            # å¤„ç†é”™è¯¯æƒ…å†µ
            if accumulated_response:
                if accumulated_response.finish_reason != types.FinishReason.STOP:
                    print(f"Gemini generation stopped due to: {accumulated_response.finish_reason.name}")
                    if accumulated_response.safety_ratings:
                        for rating in accumulated_response.safety_ratings:
                            print(f"Safety Rating: {rating.category.name} - {rating.probability.name}")
                    progress.update("error", 0, f"Geminiç”Ÿæˆåœæ­¢: {accumulated_response.finish_reason.name}")
                    return
            progress.update("error", 0, "Geminiæœªè¿”å›æœ‰æ•ˆçš„å›å¤")
            return



    except Exception as e:
        print(f"Error in process_video_task: {str(e)}")
        progress.update("error", 0, f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")


